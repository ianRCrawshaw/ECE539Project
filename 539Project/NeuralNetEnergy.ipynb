{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da012d82-fea5-451c-b6af-ba5dd1dba7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import scipy as sc\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a366dca0-1899-46fe-a8a5-0843da2c1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('flukaRunsTyped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15f5e89-6abd-41df-b65a-603d16bbf777",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRatio = 0.8\n",
    "# x is the tracklength in each bin\n",
    "# y is the log of the energy\n",
    "xfull = df.to_numpy()[:,:500]\n",
    "yfull = np.log(df.to_numpy()[:,500])\n",
    "particle_labels = df.to_numpy()[:,501:507]\n",
    "xtrain, xtest, ytrain, ytest  = train_test_split(\n",
    "    xfull, yfull, train_size=trainRatio, \n",
    "    stratify=particle_labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e00b8f8-bbfc-477b-beef-dc4aab388e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0094\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.1489e-04\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 9.9300e-05\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.8224e-05\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.8576e-05\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.7533e-05\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.0664e-05\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.6082e-05\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.2865e-05\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.0517e-05\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 8.7496e-06\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 7.3863e-06\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.3133e-06\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.4544e-06\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.7570e-06\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.1839e-06\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.7081e-06\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.3094e-06\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 2.9727e-06\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 2.6863e-06\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 2.4413e-06\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 2.2307e-06\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 2.0486e-06\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.8906e-06\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.7529e-06\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.6325e-06\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.5270e-06\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.4342e-06\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.3524e-06\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.2801e-06\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.2160e-06\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.1592e-06\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.1087e-06\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.0638e-06\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.0237e-06\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 9.8784e-07\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 9.5580e-07\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 9.2710e-07\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 9.0136e-07\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 8.7827e-07\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 8.5751e-07\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 8.3884e-07\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 8.2202e-07\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 8.0688e-07\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.9321e-07\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.8088e-07\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.6974e-07\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.5967e-07\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.5056e-07\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.4230e-07\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.3483e-07\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.2805e-07\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.2191e-07\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.1632e-07\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.1124e-07\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 7.0662e-07\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 7.0242e-07\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 6.9859e-07\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.9509e-07\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.9190e-07\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.8899e-07\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.8632e-07\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.8387e-07\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.8163e-07\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.7957e-07\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 6.7768e-07\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 6.7594e-07\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.7433e-07\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.7285e-07\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.7148e-07\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.7022e-07\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6904e-07\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6796e-07\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6695e-07\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6601e-07\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6514e-07\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6432e-07\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6355e-07\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6283e-07\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6218e-07\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6154e-07\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6097e-07\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.6040e-07\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5989e-07\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5939e-07\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5893e-07\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5849e-07\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5809e-07\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5769e-07\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5732e-07\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5697e-07\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5664e-07\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5632e-07\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5601e-07\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5572e-07\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5546e-07\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5520e-07\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5494e-07\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5471e-07\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 6.5447e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28bf01600>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_size1 = xtrain.shape[1]\n",
    "hiddenSize1 = 300\n",
    "numEpochs1 = 100\n",
    "batchSize1 = 256\n",
    "\n",
    "lInput1 = keras.Input(shape=(in_size1,))\n",
    "lEncoded1 = layers.Dense(hiddenSize1, activation='sigmoid',name='Encoder1')(lInput1)\n",
    "lDecoded1 = layers.Dense(in_size1, activation='sigmoid', name = 'Decoder1')(lEncoded1)\n",
    "\n",
    "# Full autoencoder\n",
    "autoencoder1 = keras.Model(lInput1, lDecoded1)\n",
    "# Only encoding part\n",
    "encoder1 = keras.Model(lInput1, lEncoded1)\n",
    "autoencoder1.compile(optimizer='adam', loss='MeanSquaredError')\n",
    "# Run unsupervised training on the training set. We run the training for 100 epochs.\n",
    "autoencoder1.fit(xtrain, xtrain, epochs=numEpochs1, batch_size=batchSize1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3fc05ae-92cd-49bc-a69a-9446576a93fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 350us/step\n",
      "1500/1500 [==============================] - 1s 545us/step\n"
     ]
    }
   ],
   "source": [
    "input2 = encoder1.predict(xtrain)\n",
    "xtrain2 = autoencoder1.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012a38f8-38bf-45fd-9d28-35039fcd1d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.3549e-04\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.1791e-07\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.1841e-07\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.1999e-07\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2138e-07\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2016e-07\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2029e-07\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2175e-07\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.1955e-07\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2543e-07\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2134e-07\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2135e-07\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2365e-07\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2273e-07\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2513e-07\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2707e-07\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.3172e-07\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2328e-07\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2726e-07\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.3026e-07\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.3378e-07\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.4650e-07\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.3192e-07\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6033e-07\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.5220e-07\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6504e-07\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6237e-07\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.6293e-07\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 4.8117e-07\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.7474e-07\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.7647e-07\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6619e-07\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.8340e-07\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 4.7225e-07\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 4.8290e-07\n",
      "Epoch 36/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 4.8197e-07\n",
      "Epoch 37/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.9434e-07\n",
      "Epoch 38/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6156e-07\n",
      "Epoch 39/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 5.0042e-07\n",
      "Epoch 40/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.6733e-07\n",
      "Epoch 41/100\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 4.6836e-07\n",
      "Epoch 42/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6944e-07\n",
      "Epoch 43/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6515e-07\n",
      "Epoch 44/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6490e-07\n",
      "Epoch 45/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.7372e-07\n",
      "Epoch 46/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.5251e-07\n",
      "Epoch 47/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.6347e-07\n",
      "Epoch 48/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.4759e-07\n",
      "Epoch 49/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.4614e-07\n",
      "Epoch 50/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2501e-07\n",
      "Epoch 51/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.7834e-07\n",
      "Epoch 52/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.3779e-07\n",
      "Epoch 53/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.0941e-07\n",
      "Epoch 54/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.0927e-07\n",
      "Epoch 55/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2265e-07\n",
      "Epoch 56/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.4492e-07\n",
      "Epoch 57/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.4999e-07\n",
      "Epoch 58/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2231e-07\n",
      "Epoch 59/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2544e-07\n",
      "Epoch 60/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2839e-07\n",
      "Epoch 61/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.2212e-07\n",
      "Epoch 62/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.1883e-07\n",
      "Epoch 63/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.8949e-07\n",
      "Epoch 64/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.0035e-07\n",
      "Epoch 65/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.8833e-07\n",
      "Epoch 66/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.8482e-07\n",
      "Epoch 67/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.6868e-07\n",
      "Epoch 68/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.8975e-07\n",
      "Epoch 69/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.1375e-07\n",
      "Epoch 70/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.9184e-07\n",
      "Epoch 71/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.6938e-07\n",
      "Epoch 72/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.8422e-07\n",
      "Epoch 73/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.0621e-07\n",
      "Epoch 74/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.8480e-07\n",
      "Epoch 75/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 4.1409e-07\n",
      "Epoch 76/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.6259e-07\n",
      "Epoch 77/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.7776e-07\n",
      "Epoch 78/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.4951e-07\n",
      "Epoch 79/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.7104e-07\n",
      "Epoch 80/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.7073e-07\n",
      "Epoch 81/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.6120e-07\n",
      "Epoch 82/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.6683e-07\n",
      "Epoch 83/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.5233e-07\n",
      "Epoch 84/100\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 3.7979e-07\n",
      "Epoch 85/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.3992e-07\n",
      "Epoch 86/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.5585e-07\n",
      "Epoch 87/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.5647e-07\n",
      "Epoch 88/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.4153e-07\n",
      "Epoch 89/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.9586e-07\n",
      "Epoch 90/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.4055e-07\n",
      "Epoch 91/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.3602e-07\n",
      "Epoch 92/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.2819e-07\n",
      "Epoch 93/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.4199e-07\n",
      "Epoch 94/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.3600e-07\n",
      "Epoch 95/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.2226e-07\n",
      "Epoch 96/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 3.2509e-07\n",
      "Epoch 97/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.6664e-07\n",
      "Epoch 98/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.7510e-07\n",
      "Epoch 99/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.3075e-07\n",
      "Epoch 100/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 3.1762e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28d68ea40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_size2 = input2.shape[1]\n",
    "hiddenSize2 = 300\n",
    "numEpochs2 = 100\n",
    "batchSize2 = 256\n",
    "\n",
    "lInput2 = keras.Input(shape=(in_size2,))\n",
    "lEncoded2 = layers.Dense(hiddenSize2, activation='sigmoid',name='Encoder2')(lInput2)\n",
    "lDecoded2 = layers.Dense(in_size2, activation='sigmoid', name = 'Decoder2')(lEncoded2)\n",
    "\n",
    "# Full autoencoder\n",
    "autoencoder2 = keras.Model(lInput2, lDecoded2)\n",
    "# Only encoding part\n",
    "encoder2 = keras.Model(lInput2, lEncoded2)\n",
    "autoencoder2.compile(optimizer='adam', loss='MeanSquaredError')\n",
    "# Run unsupervised training on the training set. We run the training for 100 epochs.\n",
    "autoencoder2.fit(input2, input2, epochs=numEpochs2, batch_size=batchSize2, \n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29f9ed06-289a-4d60-9146-56940816c05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 309us/step\n"
     ]
    }
   ],
   "source": [
    "input3 = encoder2.predict(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcfdf212-1b45-4f45-956a-9ba6c6490971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 6.5888\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9187\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9189\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9187\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9192\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9209\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9191\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9199\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9196\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9191\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9203\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9211\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9209\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9191\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9192\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9202\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9206\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9221\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9226\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9206\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9211\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9212\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9207\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9215\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9219\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9231\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9248\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9210\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9225\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9207\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9228\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9238\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9203\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9224\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9227\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9250\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9233\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9217\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9209\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9210\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9223\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9214\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9241\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9225\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9205\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9220\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9228\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9224\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9205\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9206\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9223\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9210\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9222\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9255\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9201\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9213\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9228\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9198\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9229\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9276\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9230\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9218\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9224\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9255\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9215\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9215\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9211\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9198\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9234\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9231\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9203\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 4.9225\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9204\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9220\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9215\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9258\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9235\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9236\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9208\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9224\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9222\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9220\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9211\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9217\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9208\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9216\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9218\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9225\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9298\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9226\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9224\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9227\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9246\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9228\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9233\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9206\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9249\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9215\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9213\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 4.9205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28e0126b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sizeFinal = input3.shape[1]\n",
    "numEpochsFinal = 100\n",
    "batchSizeFinal = 400\n",
    "\n",
    "lInputFinal = keras.Input(shape=(in_sizeFinal,))\n",
    "lFinal1 = layers.Dense(100, activation='sigmoid',name='Final1')(lInputFinal)\n",
    "lFinal2 = layers.Dense(70, activation='sigmoid',name='Final2')(lFinal1)\n",
    "lFinal3 = layers.Dense(40, activation='sigmoid',name='Final3')(lFinal2)\n",
    "lFinal4 = layers.Dense(10, activation='sigmoid',name='Final4')(lFinal3)\n",
    "lFinal = layers.Dense(1, activation=None,name='Final')(lFinal4)\n",
    "# Full autoencoder\n",
    "finalModel = keras.Model(lInputFinal, lFinal)\n",
    "opt = keras.optimizers.legacy.Adam(learning_rate=0.01)\n",
    "finalModel.compile(optimizer=opt, loss='MeanSquaredError')\n",
    "finalModel.fit(input3, ytrain, epochs=numEpochsFinal, batch_size=batchSizeFinal, \n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d78f88ee-dbb8-41cc-8232-ca84ece44ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 1s 915us/step\n"
     ]
    }
   ],
   "source": [
    "logEpred = finalModel.predict(input3).reshape(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b046fc9a-1fb0-41fc-9295-5ba6f7144f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9059019594433"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((ytrain - logEpred)**2)/ytrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a36cf3a4-8f9e-49e3-9be6-2a4024b3f8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([413.80496, 413.80496, 413.80496, ..., 413.80496, 413.80496,\n",
       "       413.80496], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Current model predicts all energy values to be the same\n",
    "np.e**logEpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0587c26-43eb-4071-ab76-afdddc71a62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
