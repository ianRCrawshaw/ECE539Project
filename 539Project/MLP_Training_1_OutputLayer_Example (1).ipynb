{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8730,
     "status": "ok",
     "timestamp": 1677474720104,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "36wZV4G372WT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from google.colab import drive\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19965,
     "status": "ok",
     "timestamp": 1677474740052,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "UBPzbcsME_ei",
    "outputId": "a920fef6-50f2-4795-8680-d79fb8981f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "with open('/content/drive/My Drive/Colab Notebooks/data/iris.csv', 'r') as f: \n",
    "  temp = np.genfromtxt(f, dtype='f4', delimiter=',')  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677474740052,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "41FxqWjuDVcm"
   },
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # The examples are read at random, in no particular order\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = tf.constant(indices[i:min(i + batch_size, num_examples)])\n",
    "        yield tf.gather(features, j), tf.gather(labels, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677474740053,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "XSCNT519s7xF"
   },
   "outputs": [],
   "source": [
    "# Optimization algorithm Stochastic Gradient Descent\n",
    "def sgd(param, grad, lr, batch_size):\n",
    "  param.assign_sub(lr * grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677474740053,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "oplV28fQ0ZTy"
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def cross_entropy(z, t):\n",
    "  # return tf.keras.losses.CategoricalCrossentropy()(t,z)            \n",
    "  return  -(1/len(z))*tf.reduce_sum(tf.math.log(z)*t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677474740053,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "WVKNCTXuBB9A"
   },
   "outputs": [],
   "source": [
    "def model(x,w):\n",
    "  # layer with softmax function  \n",
    "  u = np.hstack((np.ones((x.shape[0],1)), x))@w\n",
    "  u_exp = tf.math.exp(u)\n",
    "  z = u_exp/tf.reduce_sum(u_exp,axis=1,keepdims=True)\n",
    "  # if softmax activation is to be used, \n",
    "  # z = tf.nn.softmax(u)\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677474740054,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "ViCDki3gFPVg"
   },
   "outputs": [],
   "source": [
    "# Data Prep\n",
    "\n",
    "X = temp[:,0:-1]\n",
    "# One-hot output layer encodding\n",
    "labels = np.array(1*[temp[:,-1]==1, temp[:,-1]==2, temp[:,-1]==3]).T.astype('f4')\n",
    "\n",
    "# K: Nsamples, d: featureDimension, N: Nclasses\n",
    "K,d = X.shape\n",
    "N = labels.shape[1] \n",
    "\n",
    "# partition into 80/20% training/testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, train_size=0.8, shuffle=True, random_state=3, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677474740054,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "g0jpjWjTGP51"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 10\n",
    "lr = 0.03 # learning rate\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1677474740523,
     "user": {
      "displayName": "YU HEN HU",
      "userId": "04083449072545068296"
     },
     "user_tz": 360
    },
    "id": "VYKa1O-iFDrK",
    "outputId": "46869da1-3e49-4b12-fd96-9f1dfa714eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.483166\n",
      "epoch 2, loss 0.497220\n",
      "epoch 3, loss 0.457452\n",
      "epoch 4, loss 0.479404\n",
      "epoch 5, loss 0.427217\n",
      "epoch 6, loss 0.480973\n",
      "epoch 7, loss 0.479022\n",
      "epoch 8, loss 0.403329\n",
      "epoch 9, loss 0.420230\n",
      "epoch 10, loss 0.420937\n"
     ]
    }
   ],
   "source": [
    "# Learning\n",
    "\n",
    "w = tf.Variable(tf.random.normal(shape=(d+1,N)), trainable=True)\n",
    "for epoch in range(num_epochs):\n",
    "  for x, y in data_iter(batch_size, X_train, y_train):\n",
    "    # Feed-forward model\n",
    "    with tf.GradientTape() as g:\n",
    "      l = cross_entropy(model(x, w),y)\n",
    "    # Compute gradient on l with respect to w\n",
    "    dw = g.gradient(l, w)\n",
    "    # Update parameters using their gradient\n",
    "    sgd(w, dw, lr, batch_size)\n",
    "  # After one epoch, Evaluate resubstitution loss\n",
    "  train_loss = cross_entropy(model(tf.constant(X_train), w),y_train)\n",
    "  print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_loss)):f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THNnf8ERXqE7"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "Z_test = model(X_test,w)\n",
    "idx = np.argmax(Z_test,axis=1)\n",
    "y_pred = np.zeros((idx.size, N))\n",
    "y_pred[np.arange(idx.size),idx] = 1\n",
    "Cmat = y_test.T@y_pred\n",
    "\n",
    "print('Confusion Matrix= \\n', Cmat)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
